@inproceedings{smith2013-ismir-mirex_meta_analysis,
	Abstract = {The Music Information Retrieval Evaluation eXchange (MIREX) serves an essential function in the MIR community, but researchers have noted that the anonymity of its datasets, while useful, has made it difficult to interpret the successes and failures of the algorithms. We use the results of the 2012 MIREX Structural Segmentation task, which was accompanied by anonymous ground truth, to conduct a meta-evaluation of the algorithms. We hope this demonstrates the benefits, to both the participants and evaluators of MIREX, of releasing more data in evaluation tasks.
    Our aim is to learn more about the performance of the algorithms by studying how their success relates to properties of the annotations and recordings. We find that some evaluation metrics are redundant, and that several algorithms do not adequately model the true number of segments in typical annotations We also use publicly available ground truth to identify many of the recordings in the MIREX test sets, allowing us to identify specific pieces on which algorithms generally performed poorly and to discover where the most improvement is needed.},
	Address = {Curitiba, Brazil},
	Author = {Smith, Jordan B. L. and Chew, Elaine},
	Booktitle = {Proceedings of the International Society for Music Information Retrieval Conference},
	Pages = {251--256},
	Title = {A meta-analysis of the {MIREX Structure Segmentation} task},
	Year = {2013}}