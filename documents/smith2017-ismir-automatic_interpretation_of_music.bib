@inproceedings{smith2017-ismir-automatic_interpretation_of_music,
	Abstract = {Annotations of musical structure usually provide a low level of detail: they include boundary locations and section labels, but do not indicate what makes the sections similar or distinct, or what changes in the music at each boundary. For those studying annotated corpora, it would be useful to know the rationale for each annotation, but collecting this information from listeners is burdensome and difficult. We propose a new algorithm for estimating which musical features formed the basis for each part of an annotation. To evaluate our approach, we use a synthetic dataset of music clips, all designed to have ambiguous structure, that was previously used and validated in a psychology experiment. We find that, compared to a previous optimization-based algorithm, our correlation-based approach is better able to predict the rationale for an analysis. Using the best version of our algorithm, we process examples from the SALAMI dataset and demonstrate how we can augment the structure annotation data with estimated rationales, inviting new ways to research and use the data.},
	Address = {Suzhou, China},
	Author = {Smith, Jordan B. L. and Chew, Elaine},
	Booktitle = {Proceedings of the International Society for Music Information Retrieval Conference},
	Pages = {435--441},
	Title = {Automatic interpretation of music structure analyses: {A} validated technique for post-hoc estimation of the rationale for an annotation},
	Year = {2017}}
